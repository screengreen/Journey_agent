{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c43f3cf-32ed-49d1-813f-9f155acb9f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangSmith –æ—Ç–∫–ª—é—á–µ–Ω (–Ω–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞)\n",
      "OpenAI –∫–ª—é—á: ‚ùå –î–µ–º–æ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç\n",
      "LangSmith –∫–ª—é—á: ‚ùå –î–µ–º–æ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç\n",
      "\n",
      "–ó–∞–ø—É—Å–∫–∞—é –¢–ï–°–¢–û–í–´–ô –ø—Ä–∏–º–µ—Ä (–±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö API –≤—ã–∑–æ–≤–æ–≤)...\n",
      "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LangSmith: Failed to POST https://api.smith.langchain.com/sessions in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/sessions', '{\"detail\":\"Forbidden\"}')\n",
      "–¢–µ—Å—Ç–∏—Ä—É—é —Ä–∞–±–æ—Ç—É –∞–≥–µ–Ω—Ç–∞...\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å–æ–±—ã—Ç–∏–π: SimpleTestLLM.invoke() got an unexpected keyword argument 'config'\n",
      "\n",
      " –¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–±—ã—Ç–∏–π: 0\n",
      "\n",
      " –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n",
      "\n",
      "======================================================================\n",
      "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º OpenAI API:\n",
      "1. –ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á –Ω–∞: https://platform.openai.com/api-keys\n",
      "2. –ó–∞–º–µ–Ω–∏—Ç–µ 'sk-–≤–∞—à-—Ä–µ–∞–ª—å–Ω—ã–π-–∫–ª—é—á-–∑–¥–µ—Å—å' –Ω–∞ –≤–∞—à —Ä–µ–∞–ª—å–Ω—ã–π –∫–ª—é—á\n",
      "3. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å —Å—Ä–µ–¥—Å—Ç–≤–∞ –Ω–∞ —Å—á–µ—Ç—É OpenAI\n",
      "======================================================================\n",
      "–¢–µ—Å—Ç–∏—Ä—É—é —Ä–∞–±–æ—Ç—É –∞–≥–µ–Ω—Ç–∞...\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å–æ–±—ã—Ç–∏–π: SimpleTestLLM.invoke() got an unexpected keyword argument 'config'\n",
      "\n",
      "–¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–±—ã—Ç–∏–π: 0\n",
      "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–≥–µ–Ω—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–∞.\n",
      "\n",
      "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ LLM —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –ø–∞–∫–µ—Ç–æ–≤:\n",
      "‚Ä¢ pip install langchain-openai (–¥–ª—è OpenAI)\n",
      "‚Ä¢ pip install langchain-anthropic (–¥–ª—è Claude)\n",
      "‚Ä¢ pip install langchain-community (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_package(\"langchain-openai\")\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from typing import List, Dict, Optional, TypedDict, Union, Any\n",
    "from datetime import datetime\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç Pydantic —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π V1 –∏ V2\n",
    "try:\n",
    "    # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å V2 API\n",
    "    from pydantic import BaseModel, Field, field_validator, ConfigDict\n",
    "    PYDANTIC_V2 = True\n",
    "except ImportError:\n",
    "    # Fallback –¥–ª—è V1\n",
    "    from pydantic import BaseModel, Field, validator\n",
    "    PYDANTIC_V2 = False\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- –ù–∞—á–∞–ª–æ: –£—Å—Ç–æ–π—á–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è MemorySaver ---\n",
    "try:\n",
    "    # –ü–æ–ø—ã—Ç–∫–∞ 1: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –≤–µ—Ä—Å–∏–π LangGraph\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    CheckpointSaver = MemorySaver\n",
    "except ImportError:\n",
    "    try:\n",
    "        # –ü–æ–ø—ã—Ç–∫–∞ 2: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è –¥—Ä—É–≥–∏—Ö –≤–µ—Ä—Å–∏–π\n",
    "        from langgraph.checkpoint.memory import InMemorySaver\n",
    "        CheckpointSaver = InMemorySaver\n",
    "        print(\"INFO: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è InMemorySaver –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç.\")\n",
    "    except ImportError as e:\n",
    "        raise ImportError(\n",
    "            \"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å MemorySaver –∏–ª–∏ InMemorySaver –∏–∑ 'langgraph.checkpoint.memory'. \"\n",
    "            \"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ langgraph —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: pip install -U langgraph\"\n",
    "        ) from e\n",
    "# --- –ö–æ–Ω–µ—Ü: –£—Å—Ç–æ–π—á–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è MemorySaver ---\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç LangSmith —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫\n",
    "try:\n",
    "    from langsmith import Client, traceable, RunTree\n",
    "    LANGCHAIN_SMITH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LANGCHAIN_SMITH_AVAILABLE = False\n",
    "    print(\"WARNING: LangSmith –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞.\")\n",
    "    \n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç —Ç–∏–ø–∞ Message –∏–∑ telethon\n",
    "try:\n",
    "    from telethon.tl.types import Message as TelegramMessage\n",
    "except ImportError:\n",
    "    TelegramMessage = None\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LangSmith\n",
    "if LANGCHAIN_SMITH_AVAILABLE and os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    client = Client()\n",
    "else:\n",
    "    client = None\n",
    "\n",
    "\n",
    "class Event(BaseModel):\n",
    "    \"\"\"–ú–æ–¥–µ–ª—å —Å–æ–±—ã—Ç–∏—è –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è\"\"\"\n",
    "    title: Optional[str] = Field(None, description=\"–ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è\")\n",
    "    description: Optional[str] = Field(None, description=\"–û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è\")\n",
    "    event_type: Optional[str] = Field(None, description=\"–¢–∏–ø —Å–æ–±—ã—Ç–∏—è: –ª–µ–∫—Ü–∏—è, –≤—Å—Ç—Ä–µ—á–∞, —Å–µ–º–∏–Ω–∞—Ä –∏ —Ç.–¥.\")\n",
    "    is_online: Optional[bool] = Field(None, description=\"True - –æ–Ω–ª–∞–π–Ω, False - –æ—Ñ–ª–∞–π–Ω, None - –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ\")\n",
    "    location: Optional[str] = Field(None, description=\"–ú–µ—Å—Ç–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∏–ª–∏ —Å—Å—ã–ª–∫–∞\")\n",
    "    date: Optional[str] = Field(None, description=\"–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD\")\n",
    "    time: Optional[str] = Field(None, description=\"–í—Ä–µ–º—è —Å–æ–±—ã—Ç–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM\")\n",
    "    source_message_id: Optional[int] = Field(None, description=\"ID –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\")\n",
    "    original_text: Optional[str] = Field(None, description=\"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç\")\n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è\n",
    "    processed_at: Optional[str] = Field(None, description=\"–í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏\")\n",
    "    category: Optional[str] = Field(None, description=\"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: education, meeting, workshop, other\")\n",
    "\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Pydantic —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π V1 –∏ V2\n",
    "    if PYDANTIC_V2:\n",
    "        model_config = ConfigDict(extra=\"forbid\", arbitrary_types_allowed=True)\n",
    "        \n",
    "        # –í–∞–ª–∏–¥–∞—Ç–æ—Ä—ã –¥–ª—è Pydantic V2\n",
    "        @field_validator('date')\n",
    "        @classmethod\n",
    "        def validate_date_v2(cls, v: Optional[str]) -> Optional[str]:\n",
    "            if v:\n",
    "                try:\n",
    "                    datetime.strptime(v, '%Y-%m-%d')\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"–î–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD\")\n",
    "            return v\n",
    "        \n",
    "        @field_validator('time')\n",
    "        @classmethod\n",
    "        def validate_time_v2(cls, v: Optional[str]) -> Optional[str]:\n",
    "            if v:\n",
    "                try:\n",
    "                    datetime.strptime(v, '%H:%M')\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"–í—Ä–µ–º—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM\")\n",
    "            return v\n",
    "    else:\n",
    "        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Pydantic V1\n",
    "        class Config:\n",
    "            extra = \"forbid\"\n",
    "            arbitrary_types_allowed = True\n",
    "        \n",
    "        # –í–∞–ª–∏–¥–∞—Ç–æ—Ä—ã –¥–ª—è Pydantic V1\n",
    "        @validator('date')\n",
    "        def validate_date_v1(cls, v):\n",
    "            if v:\n",
    "                try:\n",
    "                    datetime.strptime(v, '%Y-%m-%d')\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"–î–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD\")\n",
    "            return v\n",
    "        \n",
    "        @validator('time')\n",
    "        def validate_time_v1(cls, v):\n",
    "            if v:\n",
    "                try:\n",
    "                    datetime.strptime(v, '%H:%M')\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"–í—Ä–µ–º—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM\")\n",
    "            return v\n",
    "\n",
    "    @classmethod\n",
    "    def parse_from_json(cls, json_string: str) -> List['Event']:\n",
    "        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–±—ã—Ç–∏–π –∏–∑ JSON —Å—Ç—Ä–æ–∫–∏\"\"\"\n",
    "        try:\n",
    "            parsed_data = json.loads(json_string)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}\")\n",
    "            return []\n",
    "\n",
    "        if isinstance(parsed_data, dict):\n",
    "            events_data = parsed_data.get('events', [])\n",
    "        elif isinstance(parsed_data, list):\n",
    "            events_data = parsed_data\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        events = []\n",
    "        for event_data in events_data:\n",
    "            if isinstance(event_data, dict):\n",
    "                try:\n",
    "                    if hasattr(cls, 'model_validate'):\n",
    "                        event = cls.model_validate(event_data)\n",
    "                    else:\n",
    "                        event = cls.parse_obj(event_data)\n",
    "                    events.append(event)\n",
    "                except Exception as e:\n",
    "                    print(f\"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ–±—ã—Ç–∏—è: {e}\")\n",
    "                    continue\n",
    "        return events\n",
    "\n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å\"\"\"\n",
    "        if hasattr(self, 'model_dump'):\n",
    "            return self.model_dump(exclude_none=True)\n",
    "        else:\n",
    "            return self.dict(exclude_none=True)\n",
    "\n",
    "\n",
    "class EventsList(BaseModel):\n",
    "    \"\"\"–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–æ–±—ã—Ç–∏–π\"\"\"\n",
    "    events: List[Event] = Field(default_factory=list)\n",
    "\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Pydantic —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π V1 –∏ V2\n",
    "    if PYDANTIC_V2:\n",
    "        model_config = ConfigDict(extra=\"forbid\")\n",
    "    else:\n",
    "        class Config:\n",
    "            extra = \"forbid\"\n",
    "\n",
    "\n",
    "class EventExtractor:\n",
    "    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π LangSmith —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏\"\"\"\n",
    "\n",
    "    def __init__(self, llm, model_name: str = \"gpt-4o\"):\n",
    "        self.llm = llm\n",
    "        self.model_name = model_name\n",
    "\n",
    "    @staticmethod\n",
    "    def _message_to_dict(message: Union[Dict, 'TelegramMessage']) -> Dict:\n",
    "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å\"\"\"\n",
    "        # –î–µ–∫–æ—Ä–∞—Ç–æ—Ä @traceable —É—Å–ª–æ–≤–Ω—ã–π\n",
    "        if LANGCHAIN_SMITH_AVAILABLE:\n",
    "            # –°–æ–∑–¥–∞–µ–º —É—Å–ª–æ–≤–Ω—ã–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä\n",
    "            def traceable_decorator(func):\n",
    "                def wrapper(*args, **kwargs):\n",
    "                    return func(*args, **kwargs)\n",
    "                return wrapper\n",
    "            _decorator = traceable_decorator\n",
    "        else:\n",
    "            _decorator = lambda x: x\n",
    "        \n",
    "        @_decorator\n",
    "        def _inner_message_to_dict(message: Union[Dict, 'TelegramMessage']) -> Dict:\n",
    "            if isinstance(message, dict):\n",
    "                return message\n",
    "\n",
    "            if TelegramMessage and isinstance(message, TelegramMessage):\n",
    "                return {\n",
    "                    'id': message.id,\n",
    "                    'date': message.date.isoformat() if message.date else None,\n",
    "                    'text': message.message or \"\",\n",
    "                    'sender_id': message.sender_id if hasattr(message, 'sender_id') else None,\n",
    "                    'chat_id': message.chat_id if hasattr(message, 'chat_id') else None\n",
    "                }\n",
    "\n",
    "            raise TypeError(f\"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è: {type(message)}\")\n",
    "        \n",
    "        return _inner_message_to_dict(message)\n",
    "\n",
    "    def extract_events(\n",
    "            self,\n",
    "            messages: List[Union[Dict, 'TelegramMessage']],\n",
    "            config: Optional[RunnableConfig] = None\n",
    "    ) -> List[Event]:\n",
    "        \"\"\"–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π\"\"\"\n",
    "        if not messages:\n",
    "            return []\n",
    "\n",
    "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä–∏\n",
    "        messages_dict = [self._message_to_dict(msg) for msg in messages]\n",
    "\n",
    "        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞\n",
    "        messages_text = \"\\n\\n\".join([\n",
    "            f\"–°–æ–æ–±—â–µ–Ω–∏–µ #{i + 1} (ID: {msg['id']}, –î–∞—Ç–∞: {msg['date']}):\\n{msg['text'][:1000]}\"\n",
    "            for i, msg in enumerate(messages_dict)\n",
    "        ])\n",
    "\n",
    "        prompt = f\"\"\"–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–æ–±—ã—Ç–∏—è—Ö –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.\n",
    "\n",
    "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram –∏ –∏–∑–≤–ª–µ–∫–∏ –∏–∑ –Ω–∏—Ö –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ —Å–æ–±—ã—Ç–∏—è—Ö (–ª–µ–∫—Ü–∏–∏, –≤—Å—Ç—Ä–µ—á–∏, —Å–µ–º–∏–Ω–∞—Ä—ã, –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏, –º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å—ã –∏ —Ç.–¥.).\n",
    "\n",
    "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è –∑–∞–ø–æ–ª–Ω–∏ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–ª—è:\n",
    "1. title: –∫—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è\n",
    "2. description: –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "3. event_type: —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è (–≤—ã–±–µ—Ä–∏ –∏–∑: –ª–µ–∫—Ü–∏—è, –≤—Å—Ç—Ä–µ—á–∞, —Å–µ–º–∏–Ω–∞—Ä, –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è, –º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å, –≤–µ–±–∏–Ω–∞—Ä, —ç–∫–∑–∞–º–µ–Ω, –¥–µ–¥–ª–∞–π–Ω, –ø—Ä–∞–∑–¥–Ω–∏–∫, –¥—Ä—É–≥–æ–µ)\n",
    "4. is_online: True - –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ, —á—Ç–æ —Å–æ–±—ã—Ç–∏–µ –æ–Ω–ª–∞–π–Ω; False - –µ—Å–ª–∏ –æ—Ñ–ª–∞–π–Ω; null - –µ—Å–ª–∏ –Ω–µ—è—Å–Ω–æ\n",
    "5. location: –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –º–µ—Å—Ç–æ –∏–ª–∏ —Å—Å—ã–ª–∫–∞ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è\n",
    "6. date: –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD\n",
    "7. time: –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM\n",
    "8. source_message_id: ID —Å–æ–æ–±—â–µ–Ω–∏—è, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ —Å–æ–±—ã—Ç–∏–µ\n",
    "9. original_text: —Ç–æ—á–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–±—ã—Ç–∏–∏\n",
    "\n",
    "–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:\n",
    "- –ò–∑–≤–ª–µ–∫–∞–π —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏/–¥–∞—Ç—ã\n",
    "- –ï—Å–ª–∏ –¥–∞—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è (\"–∑–∞–≤—Ç—Ä–∞\", \"–≤ —Å–ª–µ–¥—É—é—â—É—é –ø—è—Ç–Ω–∏—Ü—É\"), –ø—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–±—Å–æ–ª—é—Ç–Ω—É—é\n",
    "- –î–ª—è –æ–Ω–ª–∞–π–Ω-—Å–æ–±—ã—Ç–∏–π –≤ location —É–∫–∞–∑—ã–≤–∞–π —Å—Å—ã–ª–∫—É –∏–ª–∏ \"–æ–Ω–ª–∞–π–Ω\"\n",
    "- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –æ—Å—Ç–∞–≤–ª—è–π –ø–æ–ª–µ null\n",
    "- –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ\n",
    "\n",
    "–°–æ–æ–±—â–µ–Ω–∏—è:\n",
    "{messages_text}\n",
    "\n",
    "–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –∫–ª—é—á–æ–º \"events\", —Å–æ–¥–µ—Ä–∂–∞—â–∏–º –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤ —Å–æ–±—ã—Ç–∏–π.\n",
    "–ï—Å–ª–∏ —Å–æ–±—ã—Ç–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–µ—Ä–Ω–∏ {{\"events\": []}}.\"\"\"\n",
    "\n",
    "        try:\n",
    "            # –¢—Ä–∞—Å—Å–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ LLM —á–µ—Ä–µ–∑ LangSmith, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "            if LANGCHAIN_SMITH_AVAILABLE:\n",
    "                with self._langsmith_trace(\"llm_inference\", config) as run_tree:\n",
    "                    return self._execute_extraction(prompt, messages_dict, run_tree, config)\n",
    "            else:\n",
    "                return self._execute_extraction(prompt, messages_dict, None, config)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å–æ–±—ã—Ç–∏–π: {e}\")\n",
    "            if client:\n",
    "                client.create_feedback(\n",
    "                    run_id=None,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ LangSmith\n",
    "                    key=\"extraction_error\",\n",
    "                    score=0.0,\n",
    "                    comment=str(e)\n",
    "                )\n",
    "            return []\n",
    "\n",
    "    def _execute_extraction(self, prompt: str, messages_dict: List[Dict], \n",
    "                           run_tree: Optional[Any], config: Optional[RunnableConfig]) -> List[Event]:\n",
    "        \"\"\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π\"\"\"\n",
    "        if run_tree:\n",
    "            run_tree.inputs = {\"prompt\": prompt[:500]}\n",
    "\n",
    "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º structured output –æ—Ç OpenAI\n",
    "        if hasattr(self.llm, 'with_structured_output'):\n",
    "            structured_llm = self.llm.with_structured_output(EventsList)\n",
    "            response = structured_llm.invoke(prompt, config=config)\n",
    "            events_list = response\n",
    "        elif hasattr(self.llm, 'bind') and hasattr(self.llm, 'schema'):\n",
    "            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –¥–ª—è LangChain\n",
    "            from langchain_core.output_parsers import JsonOutputParser\n",
    "            from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "            prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "            parser = JsonOutputParser(pydantic_object=EventsList)\n",
    "\n",
    "            chain = prompt_template | self.llm | parser\n",
    "            events_list = chain.invoke({}, config=config)\n",
    "        else:\n",
    "            # Fallback –¥–ª—è –¥—Ä—É–≥–∏—Ö LLM\n",
    "            response = self.llm.invoke(prompt, config=config)\n",
    "            if hasattr(response, 'content'):\n",
    "                result_text = response.content\n",
    "            else:\n",
    "                result_text = str(response)\n",
    "\n",
    "            result_text = self._clean_json_response(result_text)\n",
    "            events = Event.parse_from_json(result_text)\n",
    "            events_list = EventsList(events=events)\n",
    "\n",
    "        events = events_list.events if events_list else []\n",
    "\n",
    "        if run_tree:\n",
    "            run_tree.outputs = {\"events_count\": len(events)}\n",
    "\n",
    "        # –û–±–æ–≥–∞—â–∞–µ–º —Å–æ–±—ã—Ç–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π\n",
    "        for idx, event in enumerate(events):\n",
    "            if not event.source_message_id and idx < len(messages_dict):\n",
    "                event.source_message_id = messages_dict[idx]['id']\n",
    "            if not event.original_text and idx < len(messages_dict):\n",
    "                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞\n",
    "                event.original_text = self._extract_relevant_text(\n",
    "                    messages_dict[idx]['text'],\n",
    "                    event\n",
    "                )\n",
    "\n",
    "        return events\n",
    "\n",
    "    @contextmanager\n",
    "    def _langsmith_trace(self, name: str, config: Optional[RunnableConfig] = None):\n",
    "        \"\"\"–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ LangSmith\"\"\"\n",
    "        if not client or not os.environ.get(\"LANGSMITH_TRACING\", \"true\").lower() == \"true\":\n",
    "            yield None\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            run_tree = RunTree(\n",
    "                name=name,\n",
    "                run_type=\"chain\",\n",
    "                inputs={},\n",
    "                outputs={},\n",
    "                serialized={},\n",
    "                project_name=os.environ.get(\"LANGSMITH_PROJECT\", \"event-miner\"),\n",
    "                tags=[\"extraction\", \"telegram\"],\n",
    "            )\n",
    "\n",
    "            if config and config.get(\"configurable\", {}).get(\"thread_id\"):\n",
    "                run_tree.thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "\n",
    "            run_tree.post()\n",
    "            yield run_tree\n",
    "\n",
    "            run_tree.end()\n",
    "            run_tree.patch()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ LangSmith: {e}\")\n",
    "            yield None\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_relevant_text(full_text: str, event: Event) -> str:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        if not event.title or len(full_text) < 200:\n",
    "            return full_text[:500]\n",
    "\n",
    "        # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ —Ç–µ–∫—Å—Ç–µ\n",
    "        title_lower = event.title.lower()\n",
    "        text_lower = full_text.lower()\n",
    "\n",
    "        if title_lower in text_lower:\n",
    "            idx = text_lower.find(title_lower)\n",
    "            start = max(0, idx - 100)\n",
    "            end = min(len(full_text), idx + len(event.title) + 200)\n",
    "            return full_text[start:end]\n",
    "\n",
    "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω\n",
    "        return full_text[:500]\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_json_response(text: str) -> str:\n",
    "        \"\"\"–û—á–∏—Å—Ç–∫–∞ JSON –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤\"\"\"\n",
    "        text = text.strip()\n",
    "\n",
    "        # –£–¥–∞–ª—è–µ–º markdown code blocks\n",
    "        if text.startswith(\"```json\"):\n",
    "            text = text[7:]\n",
    "        elif text.startswith(\"```\"):\n",
    "            text = text[3:]\n",
    "        if text.endswith(\"```\"):\n",
    "            text = text[:-3]\n",
    "\n",
    "        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã\n",
    "        text = text.strip()\n",
    "\n",
    "        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ —Ç–µ–∫—Å—Ç–µ\n",
    "        import re\n",
    "        json_pattern = r'\\{.*\"events\".*\\]\\}'\n",
    "        match = re.search(json_pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(0)\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"–°–æ—Å—Ç–æ—è–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ LangGraph\"\"\"\n",
    "    messages: List[Dict]\n",
    "    events: List[Event]\n",
    "    processed_count: int\n",
    "    extraction_errors: List[str]\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "\n",
    "class EventMinerAgent:\n",
    "    \"\"\"–û—Å–Ω–æ–≤–Ω–æ–π –∞–≥–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π —Å –ø–æ–ª–Ω–æ–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–µ–π LangGraph\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            llm,\n",
    "            event_extractor: Optional[EventExtractor] = None,\n",
    "            checkpoint_memory: bool = True\n",
    "    ):\n",
    "        self.llm = llm\n",
    "        self.event_extractor = event_extractor or EventExtractor(llm)\n",
    "\n",
    "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç–æ–π—á–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è checkpointer\n",
    "        self.checkpointer = CheckpointSaver() if checkpoint_memory else None\n",
    "\n",
    "        self.graph = self._build_graph()\n",
    "        self._setup_langsmith()\n",
    "\n",
    "    def _setup_langsmith(self):\n",
    "        \"\"\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ LangSmith –∫–ª–∏–µ–Ω—Ç–∞\"\"\"\n",
    "        if client and os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "            try:\n",
    "                # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç\n",
    "                project_name = os.environ.get(\"LANGSMITH_PROJECT\", \"event-miner-agent\")\n",
    "                client.create_project(\n",
    "                    project_name=project_name,\n",
    "                    description=\"–ê–≥–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π –∏–∑ Telegram —Å–æ–æ–±—â–µ–Ω–∏–π\"\n",
    "                )\n",
    "                print(f\"LangSmith –ø—Ä–æ–µ–∫—Ç '{project_name}' –Ω–∞—Å—Ç—Ä–æ–µ–Ω\")\n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LangSmith: {e}\")\n",
    "\n",
    "    def _build_graph(self) -> StateGraph:\n",
    "        \"\"\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ LangGraph\"\"\"\n",
    "        workflow = StateGraph(AgentState)\n",
    "\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã\n",
    "        workflow.add_node(\"preprocess_messages\", self._preprocess_messages_node)\n",
    "        workflow.add_node(\"extract_events\", self._extract_events_node)\n",
    "        workflow.add_node(\"validate_events\", self._validate_events_node)\n",
    "        workflow.add_node(\"enrich_events\", self._enrich_events_node)\n",
    "        workflow.add_node(\"handle_errors\", self._handle_errors_node)\n",
    "\n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ç–æ–∫\n",
    "        workflow.set_entry_point(\"preprocess_messages\")\n",
    "\n",
    "        # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫\n",
    "        workflow.add_edge(\"preprocess_messages\", \"extract_events\")\n",
    "        workflow.add_edge(\"extract_events\", \"validate_events\")\n",
    "        workflow.add_edge(\"validate_events\", \"enrich_events\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"enrich_events\",\n",
    "            self._should_handle_errors,\n",
    "            {\n",
    "                \"continue\": END,\n",
    "                \"handle_errors\": \"handle_errors\"\n",
    "            }\n",
    "        )\n",
    "        workflow.add_edge(\"handle_errors\", END)\n",
    "\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ö–∞–Ω–∏–∑–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω\n",
    "        if self.checkpointer:\n",
    "            return workflow.compile(checkpointer=self.checkpointer)\n",
    "        return workflow.compile()\n",
    "\n",
    "    def _preprocess_messages_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π\"\"\"\n",
    "        # –î–µ–∫–æ—Ä–∞—Ç–æ—Ä @traceable —É—Å–ª–æ–≤–Ω—ã–π\n",
    "        if LANGCHAIN_SMITH_AVAILABLE:\n",
    "            # –°–æ–∑–¥–∞–µ–º —É—Å–ª–æ–≤–Ω—ã–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä\n",
    "            def traceable_decorator(name, run_type):\n",
    "                def decorator(func):\n",
    "                    def wrapper(*args, **kwargs):\n",
    "                        return func(*args, **kwargs)\n",
    "                    return wrapper\n",
    "                return decorator\n",
    "            _decorator = traceable_decorator(\"preprocess_messages\", \"chain\")\n",
    "        else:\n",
    "            _decorator = lambda x: x\n",
    "        \n",
    "        @_decorator\n",
    "        def _inner_preprocess_messages(state: AgentState) -> AgentState:\n",
    "            messages = state.get(\"messages\", [])\n",
    "\n",
    "            if not messages:\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"extraction_errors\": [\"–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\"]\n",
    "                }\n",
    "\n",
    "            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n",
    "            filtered_messages = [\n",
    "                msg for msg in messages\n",
    "                if msg.get('text') and len(msg.get('text', '').strip()) > 10\n",
    "            ]\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"messages\": filtered_messages,\n",
    "                \"metadata\": {\n",
    "                    \"total_messages\": len(messages),\n",
    "                    \"filtered_messages\": len(filtered_messages),\n",
    "                    \"filtered_out\": len(messages) - len(filtered_messages)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        return _inner_preprocess_messages(state)\n",
    "\n",
    "    def _extract_events_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π\"\"\"\n",
    "        if LANGCHAIN_SMITH_AVAILABLE:\n",
    "            def traceable_decorator(name, run_type):\n",
    "                def decorator(func):\n",
    "                    def wrapper(*args, **kwargs):\n",
    "                        return func(*args, **kwargs)\n",
    "                    return wrapper\n",
    "                return decorator\n",
    "            _decorator = traceable_decorator(\"extract_events\", \"chain\")\n",
    "        else:\n",
    "            _decorator = lambda x: x\n",
    "        \n",
    "        @_decorator\n",
    "        def _inner_extract_events(state: AgentState) -> AgentState:\n",
    "            messages = state.get(\"messages\", [])\n",
    "\n",
    "            if not messages:\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"events\": [],\n",
    "                    \"processed_count\": 0\n",
    "                }\n",
    "\n",
    "            try:\n",
    "                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–±—ã—Ç–∏—è —Å –ø–æ–º–æ—â—å—é EventExtractor\n",
    "                events = self.event_extractor.extract_events(messages)\n",
    "\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"events\": events,\n",
    "                    \"processed_count\": len(messages)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                error_msg = f\"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π: {str(e)}\"\n",
    "                return {\n",
    "                    **state,\n",
    "                    \"events\": [],\n",
    "                    \"processed_count\": 0,\n",
    "                    \"extraction_errors\": [error_msg]\n",
    "                }\n",
    "        \n",
    "        return _inner_extract_events(state)\n",
    "\n",
    "    def _validate_events_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"–í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π\"\"\"\n",
    "        if LANGCHAIN_SMITH_AVAILABLE:\n",
    "            def traceable_decorator(name, run_type):\n",
    "                def decorator(func):\n",
    "                    def wrapper(*args, **kwargs):\n",
    "                        return func(*args, **kwargs)\n",
    "                    return wrapper\n",
    "                return decorator\n",
    "            _decorator = traceable_decorator(\"validate_events\", \"chain\")\n",
    "        else:\n",
    "            _decorator = lambda x: x\n",
    "        \n",
    "        @_decorator\n",
    "        def _inner_validate_events(state: AgentState) -> AgentState:\n",
    "            events = state.get(\"events\", [])\n",
    "            errors = state.get(\"extraction_errors\", [])\n",
    "\n",
    "            validated_events = []\n",
    "            for event in events:\n",
    "                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–æ–±—ã—Ç–∏—é\n",
    "                if (event.title or event.description) and (event.date or event.time):\n",
    "                    validated_events.append(event)\n",
    "                elif event.title and event.event_type:\n",
    "                    validated_events.append(event)\n",
    "                else:\n",
    "                    errors.append(f\"–°–æ–±—ã—Ç–∏–µ –±–µ–∑ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {event.title}\")\n",
    "\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "            metadata = state.get(\"metadata\", {})\n",
    "            metadata[\"validated_events\"] = len(validated_events)\n",
    "            metadata[\"rejected_events\"] = len(events) - len(validated_events)\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"events\": validated_events,\n",
    "                \"extraction_errors\": errors,\n",
    "                \"metadata\": metadata\n",
    "            }\n",
    "        \n",
    "        return _inner_validate_events(state)\n",
    "\n",
    "    def _enrich_events_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"–û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π\"\"\"\n",
    "        if LANGCHAIN_SMITH_AVAILABLE:\n",
    "            def traceable_decorator(name, run_type):\n",
    "                def decorator(func):\n",
    "                    def wrapper(*args, **kwargs):\n",
    "                        return func(*args, **kwargs)\n",
    "                    return wrapper\n",
    "                return decorator\n",
    "            _decorator = traceable_decorator(\"enrich_events\", \"chain\")\n",
    "        else:\n",
    "            _decorator = lambda x: x\n",
    "        \n",
    "        @_decorator\n",
    "        def _inner_enrich_events(state: AgentState) -> AgentState:\n",
    "            events = state.get(\"events\", [])\n",
    "            errors = state.get(\"extraction_errors\", [])\n",
    "\n",
    "            enriched_events = []\n",
    "            for event in events:\n",
    "                try:\n",
    "                    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "                    event_dict = event.to_dict()\n",
    "                    event_dict[\"processed_at\"] = datetime.now().isoformat()\n",
    "\n",
    "                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å–æ–±—ã—Ç–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞\n",
    "                    event_type = event.event_type or \"\"\n",
    "                    type_lower = event_type.lower()\n",
    "                    if any(word in type_lower for word in [\"–ª–µ–∫—Ü–∏—è\", \"—Å–µ–º–∏–Ω–∞—Ä\", \"–≤–µ–±–∏–Ω–∞—Ä\"]):\n",
    "                        event_dict[\"category\"] = \"education\"\n",
    "                    elif any(word in type_lower for word in [\"–≤—Å—Ç—Ä–µ—á–∞\", \"–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è\"]):\n",
    "                        event_dict[\"category\"] = \"meeting\"\n",
    "                    elif any(word in type_lower for word in [\"–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å\", \"–≤–æ—Ä–∫—à–æ–ø\"]):\n",
    "                        event_dict[\"category\"] = \"workshop\"\n",
    "                    else:\n",
    "                        event_dict[\"category\"] = \"other\"\n",
    "\n",
    "                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç Event —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–æ–ª—è–º–∏\n",
    "                    enriched_event = Event(**event_dict)\n",
    "                    enriched_events.append(enriched_event)\n",
    "\n",
    "                except Exception as e:\n",
    "                    errors.append(f\"–û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏—è {event.title}: {str(e)}\")\n",
    "                    enriched_events.append(event)  # –û—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"events\": enriched_events,\n",
    "                \"extraction_errors\": errors\n",
    "            }\n",
    "        \n",
    "        return _inner_enrich_events(state)\n",
    "\n",
    "    def _handle_errors_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫\"\"\"\n",
    "        errors = state.get(\"extraction_errors\", [])\n",
    "\n",
    "        if errors and client:\n",
    "            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –≤ LangSmith\n",
    "            for error in errors:\n",
    "                try:\n",
    "                    client.create_feedback(\n",
    "                        run_id=None,\n",
    "                        key=\"processing_error\",\n",
    "                        score=0.0,\n",
    "                        comment=error[:500]\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _should_handle_errors(self, state: AgentState) -> str:\n",
    "        \"\"\"–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏\"\"\"\n",
    "        errors = state.get(\"extraction_errors\", [])\n",
    "        return \"handle_errors\" if errors else \"continue\"\n",
    "\n",
    "    def process_messages(\n",
    "            self,\n",
    "            messages: List[Union[Dict, 'TelegramMessage']],\n",
    "            config: Optional[RunnableConfig] = None\n",
    "    ) -> List[Event]:\n",
    "        \"\"\"–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π\"\"\"\n",
    "        if LANGCHAIN_SMITH_AVAILABLE:\n",
    "            def traceable_decorator(name, run_type):\n",
    "                def decorator(func):\n",
    "                    def wrapper(*args, **kwargs):\n",
    "                        return func(*args, **kwargs)\n",
    "                    return wrapper\n",
    "                return decorator\n",
    "            _decorator = traceable_decorator(\"process_messages\", \"chain\")\n",
    "        else:\n",
    "            _decorator = lambda x: x\n",
    "        \n",
    "        @_decorator\n",
    "        def _inner_process_messages(messages: List[Union[Dict, 'TelegramMessage']], \n",
    "                                   config: Optional[RunnableConfig] = None) -> List[Event]:\n",
    "            messages_dict = [\n",
    "                EventExtractor._message_to_dict(msg) for msg in messages\n",
    "            ]\n",
    "\n",
    "            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ config –¥–ª—è checkpointer, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ\n",
    "            current_config = config\n",
    "            if self.checkpointer:\n",
    "                if current_config and current_config.get(\"configurable\"):\n",
    "                    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª configurable, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å\n",
    "                    pass\n",
    "                else:\n",
    "                    if not current_config:\n",
    "                        current_config = {}\n",
    "                    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π thread_id –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö—ç—à–∞ —Å–æ–æ–±—â–µ–Ω–∏–π\n",
    "                    messages_str = json.dumps(messages_dict, sort_keys=True, default=str)\n",
    "                    thread_hash = hashlib.md5(messages_str.encode()).hexdigest()[:10]\n",
    "                    current_config = {**current_config, \"configurable\": {\"thread_id\": f\"temp_{thread_hash}\"}}\n",
    "\n",
    "            initial_state: AgentState = {\n",
    "                \"messages\": messages_dict,\n",
    "                \"events\": [],\n",
    "                \"processed_count\": 0,\n",
    "                \"extraction_errors\": [],\n",
    "                \"metadata\": {}\n",
    "            }\n",
    "\n",
    "            # –í—ã–ø–æ–ª–Ω—è–µ–º –≥—Ä–∞—Ñ\n",
    "            final_state = self.graph.invoke(initial_state, config=current_config)\n",
    "\n",
    "            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ LangSmith\n",
    "            if client:\n",
    "                try:\n",
    "                    events_count = len(final_state.get(\"events\", []))\n",
    "                    client.create_feedback(\n",
    "                        run_id=None,\n",
    "                        key=\"events_extracted\",\n",
    "                        score=min(1.0, events_count / 10.0),  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä\n",
    "                        comment=f\"–ò–∑–≤–ª–µ—á–µ–Ω–æ {events_count} —Å–æ–±—ã—Ç–∏–π\"\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            return final_state.get(\"events\", [])\n",
    "        \n",
    "        return _inner_process_messages(messages, config)\n",
    "\n",
    "    def process_messages_batch(\n",
    "            self,\n",
    "            messages: List[Union[Dict, 'TelegramMessage']],\n",
    "            batch_size: int = 10,\n",
    "            config: Optional[RunnableConfig] = None\n",
    "    ) -> List[Event]:\n",
    "        \"\"\"–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π\"\"\"\n",
    "        if LANGCHAIN_SMITH_AVAILABLE:\n",
    "            def traceable_decorator(name, run_type):\n",
    "                def decorator(func):\n",
    "                    def wrapper(*args, **kwargs):\n",
    "                        return func(*args, **kwargs)\n",
    "                    return wrapper\n",
    "                return decorator\n",
    "            _decorator = traceable_decorator(\"process_messages_batch\", \"chain\")\n",
    "        else:\n",
    "            _decorator = lambda x: x\n",
    "        \n",
    "        @_decorator\n",
    "        def _inner_process_messages_batch(messages: List[Union[Dict, 'TelegramMessage']],\n",
    "                                         batch_size: int = 10,\n",
    "                                         config: Optional[RunnableConfig] = None) -> List[Event]:\n",
    "            all_events = []\n",
    "\n",
    "            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ config –¥–ª—è checkpointer, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ\n",
    "            current_config = config\n",
    "            if self.checkpointer:\n",
    "                if current_config and current_config.get(\"configurable\"):\n",
    "                    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª configurable, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å\n",
    "                    pass\n",
    "                else:\n",
    "                    if not current_config:\n",
    "                        current_config = {}\n",
    "                    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π thread_id –¥–ª—è –≤—Å–µ–≥–æ –±–∞—Ç—á–∞\n",
    "                    all_messages_str = json.dumps(messages, sort_keys=True, default=str)\n",
    "                    thread_hash = hashlib.md5(all_messages_str.encode()).hexdigest()[:10]\n",
    "                    current_config = {**current_config, \"configurable\": {\"thread_id\": f\"batch_{thread_hash}\"}}\n",
    "\n",
    "            for i in range(0, len(messages), batch_size):\n",
    "                batch = messages[i:i + batch_size]\n",
    "                # –ü–µ—Ä–µ–¥–∞–µ–º –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ config –≤–æ –≤—Å–µ –≤—ã–∑–æ–≤—ã process_messages\n",
    "                events = self.process_messages(batch, config=current_config)\n",
    "                all_events.extend(events)\n",
    "\n",
    "                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏\n",
    "                if i + batch_size < len(messages):\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "            return all_events\n",
    "        \n",
    "        return _inner_process_messages_batch(messages, batch_size, config)\n",
    "\n",
    "    def get_graph_info(self) -> Dict:\n",
    "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≥—Ä–∞—Ñ–µ\"\"\"\n",
    "        return {\n",
    "            \"nodes\": list(self.graph.nodes),\n",
    "            \"edges\": list(self.graph.edges),\n",
    "            \"has_checkpointer\": self.checkpointer is not None,\n",
    "            \"langsmith_enabled\": client is not None\n",
    "        }\n",
    "\n",
    "\n",
    "# –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞\n",
    "def create_event_miner_agent(\n",
    "        llm,\n",
    "        model_name: str = \"gpt-4o\",\n",
    "        enable_langsmith: bool = True,\n",
    "        checkpoint_memory: bool = True\n",
    ") -> EventMinerAgent:\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π\n",
    "\n",
    "    Args:\n",
    "        llm: –ú–æ–¥–µ–ª—å LLM (OpenAI, LangChain –∏ —Ç.–¥.)\n",
    "        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        enable_langsmith: –í–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É LangSmith\n",
    "        checkpoint_memory: –í–∫–ª—é—á–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã –ø–∞–º—è—Ç–∏\n",
    "\n",
    "    Returns:\n",
    "        EventMinerAgent: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç\n",
    "    \"\"\"\n",
    "    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º LangSmith\n",
    "    if enable_langsmith and not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "        print(\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: LANGSMITH_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞.\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∏ –∞–≥–µ–Ω—Ç\n",
    "    extractor = EventExtractor(llm, model_name)\n",
    "    agent = EventMinerAgent(llm, extractor, checkpoint_memory)\n",
    "\n",
    "    return agent\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å –†–ï–ê–õ–¨–ù–´–ú OpenAI –∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º LangSmith\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üöÄ EVENT MINER AGENT - –†–ï–ê–õ–¨–ù–´–ô –†–ï–ñ–ò–ú –° LANGSMITH\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # ========== –ü–†–û–í–ï–†–ö–ê –ò –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô ==========\n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        print(\"‚úÖ langchain-openai —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå langchain-openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "        print(\"–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langchain-openai\"])\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        print(\"‚úÖ langchain-openai —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "    \n",
    "    try:\n",
    "        from langsmith import Client\n",
    "        print(\"‚úÖ langsmith —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå langsmith –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "        print(\"–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langsmith\"])\n",
    "        from langsmith import Client\n",
    "        print(\"‚úÖ langsmith —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "    \n",
    "    # ========== –ü–†–û–í–ï–†–ö–ê –†–ï–ê–õ–¨–ù–´–• –ö–õ–Æ–ß–ï–ô ==========\n",
    "    print(\"\\nüîê –ü–†–û–í–ï–†–ö–ê API –ö–õ–Æ–ß–ï–ô:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # –ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á–∏ –∑–¥–µ—Å—å –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "    OPENAI_API_KEY = input(\"–í–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenAI API –∫–ª—é—á (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å sk-): \").strip()\n",
    "    LANGSMITH_API_KEY = input(\"–í–≤–µ–¥–∏—Ç–µ –≤–∞—à LangSmith API –∫–ª—é—á (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å ls-): \").strip()\n",
    "    \n",
    "    if not OPENAI_API_KEY.startswith('sk-'):\n",
    "        print(\"‚ùå –ù–ï–í–ï–†–ù–´–ô OPENAI –ö–õ–Æ–ß! –î–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'sk-'\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if not LANGSMITH_API_KEY.startswith('ls-'):\n",
    "        print(\"‚ùå –ù–ï–í–ï–†–ù–´–ô LANGSMITH –ö–õ–Æ–ß! –î–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'ls-'\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª—é—á–∏\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "    os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = \"event-miner-agent-production\"\n",
    "    \n",
    "    print(\" –ö–ª—é—á–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏ –≤–∞–ª–∏–¥–Ω—ã\")\n",
    "    \n",
    "    # ========== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LANGSMITH ==========\n",
    "    print(\"\\nüìä –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LANGSMITH...\")\n",
    "    try:\n",
    "        client = Client()\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å LangSmith\n",
    "        test_project = \"event-miner-test-init\"\n",
    "        try:\n",
    "            client.create_project(project_name=test_project)\n",
    "            print(f\" LangSmith –ø—Ä–æ–µ–∫—Ç '{test_project}' —Å–æ–∑–¥–∞–Ω\")\n",
    "        except:\n",
    "            # –ü—Ä–æ–µ–∫—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ\n",
    "            print(f\" LangSmith –ø–æ–¥–∫–ª—é—á–µ–Ω (–ø—Ä–æ–µ–∫—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)\")\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "        user_info = client.get_user_info()\n",
    "        print(f\" LangSmith –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –∫–∞–∫: {user_info.get('email', 'unknown')}\")\n",
    "        print(\" LangSmith —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –ê–ö–¢–ò–í–ò–†–û–í–ê–ù–ê\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LangSmith: {e}\")\n",
    "        print(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\")\n",
    "        print(\"1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ LangSmith\")\n",
    "        print(\"2. –î–æ—Å—Ç—É–ø –∫ https://api.smith.langchain.com\")\n",
    "        print(\"3. –ê–∫–∫–∞—É–Ω—Ç LangSmith –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # ========== –°–û–ó–î–ê–ù–ò–ï –†–ï–ê–õ–¨–ù–û–ô LLM ==========\n",
    "    print(\"\\n –°–û–ó–î–ê–ù–ò–ï –†–ï–ê–õ–¨–ù–û–ô LLM –ú–û–î–ï–õ–ò...\")\n",
    "    try:\n",
    "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º gpt-3.5-turbo –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤ –Ω–∞—á–∞–ª–µ\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.3,\n",
    "            max_tokens=1000,\n",
    "            timeout=30,\n",
    "            max_retries=2\n",
    "        )\n",
    "        print(\" –ú–æ–¥–µ–ª—å gpt-3.5-turbo —Å–æ–∑–¥–∞–Ω–∞\")\n",
    "        \n",
    "        # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ OpenAI\n",
    "        print(\"   –ü—Ä–æ–≤–µ—Ä—è—é —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å OpenAI...\")\n",
    "        test_response = llm.invoke(\"–û—Ç–≤–µ—Ç—å 'OK' –µ—Å–ª–∏ —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å\")\n",
    "        if hasattr(test_response, 'content'):\n",
    "            print(\"    OpenAI –æ—Ç–≤–µ—á–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ\")\n",
    "        else:\n",
    "            print(\"     –ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è LLM: {e}\")\n",
    "        print(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\")\n",
    "        print(\"1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å OpenAI API –∫–ª—é—á–∞\")\n",
    "        print(\"2. –ë–∞–ª–∞–Ω—Å –Ω–∞ —Å—á–µ—Ç—É OpenAI\")\n",
    "        print(\"3. –î–æ—Å—Ç—É–ø –∫ https://api.openai.com\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # ========== –°–û–ó–î–ê–ù–ò–ï –ê–ì–ï–ù–¢–ê –° LANGSMITH ==========\n",
    "    print(\"\\n –°–û–ó–î–ê–ù–ò–ï AGENT –° –í–ö–õ–Æ–ß–ï–ù–ù–´–ú LANGSMITH...\")\n",
    "    try:\n",
    "        agent = create_event_miner_agent(\n",
    "            llm=llm,\n",
    "            model_name=\"gpt-3.5-turbo\",\n",
    "            enable_langsmith=True,  #\n",
    "            checkpoint_memory=True\n",
    "        )\n",
    "        print(\" Agent —Å–æ–∑–¥–∞–Ω —Å –≤–∫–ª—é—á–µ–Ω–Ω–æ–π —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–æ–π LangSmith\")\n",
    "        print(f\"   ‚Ä¢ Graph nodes: {len(agent.get_graph_info()['nodes'])}\")\n",
    "        print(f\"   ‚Ä¢ Checkpointer: {'‚úÖ' if agent.get_graph_info()['has_checkpointer'] else '‚ùå'}\")\n",
    "        print(f\"   ‚Ä¢ LangSmith: {'‚úÖ' if agent.get_graph_info()['langsmith_enabled'] else '‚ùå'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # ========== –¢–ï–°–¢–û–í–´–ô –ó–ê–ü–†–û–° ==========\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" –í–´–ü–û–õ–ù–ï–ù–ò–ï –¢–ï–°–¢–û–í–û–ì–û –ó–ê–ü–†–û–°–ê –° LANGSMITH –¢–†–ê–°–°–ò–†–û–í–ö–û–ô\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    test_messages = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"date\": \"2024-01-15T10:30:00\",\n",
    "            \"text\": \"–ó–∞–≤—Ç—Ä–∞ –≤ 15:00 –±—É–¥–µ—Ç –æ–Ω–ª–∞–π–Ω-–ª–µ–∫—Ü–∏—è –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö. –°—Å—ã–ª–∫–∞ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: meet.google.com/abc-defg-hij. –ü—Ä–∏–Ω–æ—Å–∏—Ç–µ –Ω–æ—É—Ç–±—É–∫–∏.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"date\": \"2024-01-15T11:00:00\",\n",
    "            \"text\": \"–í–ê–ñ–ù–û: –ü–ª–∞–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–µ —Å–æ–≤–µ—â–∞–Ω–∏–µ –ø–æ –ø—Ä–æ–µ–∫—Ç—É '–ù–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å' –≤ —Å—Ä–µ–¥—É 17 —è–Ω–≤–∞—Ä—è –≤ 11:00 –≤ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü-–∑–∞–ª–µ ‚Ññ5 (3 —ç—Ç–∞–∂). –ë—É–¥—É—Ç –æ–±—Å—É–∂–¥–∞—Ç—å—Å—è –º–∞–∫–µ—Ç—ã.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"date\": \"2024-01-15T12:00:00\",\n",
    "            \"text\": \"–ù–∞–ø–æ–º–∏–Ω–∞—é –ø—Ä–æ –¥–µ–¥–ª–∞–π–Ω —Å–¥–∞—á–∏ –æ—Ç—á–µ—Ç–æ–≤ –ø–æ –∫–≤–∞—Ä—Ç–∞–ª—É - –¥–æ –ø—è—Ç–Ω–∏—Ü—ã, 19 —è–Ω–≤–∞—Ä—è, 18:00. –û—Ç–ø—Ä–∞–≤–ª—è—Ç—å –Ω–∞ report@company.com\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\" –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {len(test_messages)} —Å–æ–æ–±—â–µ–Ω–∏—è...\")\n",
    "    print(\"   (—Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ LangSmith –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏)\")\n",
    "    \n",
    "    try:\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        events = agent.process_messages(test_messages)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\" –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {elapsed_time:.2f} —Å–µ–∫\")\n",
    "        \n",
    "        print(f\"\\n –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if events:\n",
    "            print(f\" –ù–∞–π–¥–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π: {len(events)}\")\n",
    "            \n",
    "            for i, event in enumerate(events, 1):\n",
    "                print(f\"\\n{i}. [{event.event_type or '—Å–æ–±—ã—Ç–∏–µ'}] {event.title or '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'}\")\n",
    "                print(f\"    –î–∞—Ç–∞: {event.date or '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'} {event.time or ''}\")\n",
    "                print(f\"    –ú–µ—Å—Ç–æ: {event.location or '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'}\")\n",
    "                print(f\"    –§–æ—Ä–º–∞—Ç: {' –û–Ω–ª–∞–π–Ω' if event.is_online else ' –û—Ñ–ª–∞–π–Ω' if event.is_online is False else '‚ö™ –ù–µ—è—Å–Ω–æ'}\")\n",
    "                if event.description:\n",
    "                    desc = event.description[:80] + \"...\" if len(event.description) > 80 else event.description\n",
    "                    print(f\"    –û–ø–∏—Å–∞–Ω–∏–µ: {desc}\")\n",
    "                print(f\"    Source ID: {event.source_message_id}\")\n",
    "                \n",
    "        else:\n",
    "            print(\"  –°–æ–±—ã—Ç–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\")\n",
    "            \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\" LANGSMITH –¢–†–ê–°–°–ò–†–û–í–ö–ê –ê–ö–¢–ò–í–ù–ê!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"\\n–û—Ç–∫—Ä–æ–π—Ç–µ –¥–∞—à–±–æ—Ä–¥ LangSmith –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏:\")\n",
    "        print(f\" https://smith.langchain.com/o/{client.get_workspace()}/projects/p/event-miner-agent-production\")\n",
    "        print(\"\\n–ù–∞ –¥–∞—à–±–æ—Ä–¥–µ –≤—ã —É–≤–∏–¥–∏—Ç–µ:\")\n",
    "        print(\"‚Ä¢ –ü–æ–ª–Ω—ã–π –≥—Ä–∞—Ñ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞\")\n",
    "        print(\"‚Ä¢ –ó–∞—Ç—Ä–∞—Ç—ã —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤\")\n",
    "        print(\"‚Ä¢ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞\")\n",
    "        print(\"‚Ä¢ –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è\")\n",
    "        print(\"‚Ä¢ –í–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}\")\n",
    "        print(\"\\n–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ LangSmith\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ========== –ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ==========\n",
    "    print(\"\\n –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ:\")\n",
    "    print(\"1. –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–≤–æ–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤—ã–∑–æ–≤–∏—Ç–µ:\")\n",
    "    print(\"   events = agent.process_messages(–≤–∞—à–∏_—Å–æ–æ–±—â–µ–Ω–∏—è)\")\n",
    "    print(\"2. –í—Å–µ –≤—ã–∑–æ–≤—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ç—Ä–∞—Å—Å–∏—Ä—É—é—Ç—Å—è –≤ LangSmith\")\n",
    "    print(\"3. –î–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:\")\n",
    "    print(\"   events = agent.process_messages_batch(—Å–æ–æ–±—â–µ–Ω–∏—è, batch_size=5)\")\n",
    "    print(\"4. –û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –∑–∞—Ç—Ä–∞—Ç—ã –≤ OpenAI: https://platform.openai.com/usage\")\n",
    "    print(\"5. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –≤ LangSmith\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3883d11-d264-4cfe-8730-9b51e2ae8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_package(\"langchain-openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d4ec7d-e41e-4ffe-b962-91ceb2877529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961a1a0-e4d0-454a-9b56-52169046cba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
