from __future__ import annotations

import os
from typing import Any, List, Optional, Type, TypeVar, Literal

from pydantic import BaseModel
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage, AIMessage, ToolMessage
from langchain_openai import ChatOpenAI
from langchain_mistralai import ChatMistralAI


T = TypeVar("T", bound=BaseModel)


class JourneyLLM:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è LLM-–º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞:
    - —Å–∞–º–∞ –≤—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ env:
        * –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ OPENAI_API_KEY ‚Üí openai
        * –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ MISTRAL_API_KEY ‚Üí mistral
        * –µ—Å–ª–∏ –µ—Å—Ç—å –æ–±–∞ ‚Üí openai
        * –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ ‚Üí –æ—à–∏–±–∫–∞
    - –≤–Ω—É—Ç—Ä–∏ –¥–µ—Ä–∂–∏—Ç LangChain-–º–æ–¥–µ–ª—å (ChatOpenAI –∏–ª–∏ ChatMistralAI)
      –≤ –∞—Ç—Ä–∏–±—É—Ç–µ `.llm`
    - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
        * .invoke() / .stream() / .bind_tools() –∏ —Ç.–ø. (—á–µ—Ä–µ–∑ __getattr__)
        * .parse(output_model, user_prompt, system_prompt, web_context)
    """

    def __init__(
        self,
        provider: Optional[Literal["openai", "mistral"]] = None,
        model: Optional[str] = None,
        temperature: float = 0.2,
    ) -> None:
        self.provider = provider or self._detect_provider_from_env()

        if self.provider == "openai":
            self.model = model or "gpt-4o"
            self.llm = ChatOpenAI(
                model=self.model,
                temperature=temperature,
            )
        elif self.provider == "mistral":
            self.model = model or "open-mistral-7b"
            self.llm = ChatMistralAI(
                model=self.model,
                temperature=temperature,
            )
        else:
            raise ValueError(f"Unknown provider: {self.provider}")

    @staticmethod
    def _detect_provider_from_env() -> Literal["openai", "mistral"]:
        openai_key = os.getenv("OPENAI_API_KEY")
        mistral_key = os.getenv("MISTRAL_API_KEY")

        if openai_key and not mistral_key:
            return "openai"
        if mistral_key and not openai_key:
            return "mistral"
        if openai_key and mistral_key:
            return "openai"

        raise RuntimeError(
            "No LLM API keys found. "
            "Set at least one of: OPENAI_API_KEY or MISTRAL_API_KEY."
        )

    def parse(
        self,
        output_model: Type[T],
        user_prompt: str,
        system_prompt: Optional[str] = None,
        web_context: Optional[str] = None,
        tools: Optional[List[Any]] = None,
    ) -> T:
        """
        –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ with_structured_output —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
        –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, LLM –º–æ–∂–µ—Ç –∏—Ö –≤—ã–∑—ã–≤–∞—Ç—å –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
        
        –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
            result = llm.parse(MySchema, "–°–¥–µ–ª–∞–π —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö", tools=[...])
        """
        messages: List[BaseMessage] = []

        if system_prompt:
            messages.append(SystemMessage(content=system_prompt))

        if web_context:
            messages.append(
                SystemMessage(
                    content=(
                        "–í–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, —Å–æ–±—Ä–∞–Ω–Ω—ã–π –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. "
                        "–ò—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ:\n\n" + web_context
                    )
                )
            )

        messages.append(HumanMessage(content=user_prompt))

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π tool calls
        if tools:
            return self._parse_with_tools(output_model, messages, tools)
        
        # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π structured output
        structured = self.llm.with_structured_output(output_model)
        result: T = structured.invoke(messages)
        return result
    
    def _parse_with_tools(
        self,
        output_model: Type[T],
        messages: List[BaseMessage],
        tools: List[Any],
        max_iterations: int = 10
    ) -> T:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç tool calls –≤ —Ü–∏–∫–ª–µ.
        """
        llm_with_tools = self.llm.bind_tools(tools)
        tool_map = {tool.name: tool for tool in tools}
        
        for iteration in range(max_iterations):
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
            response = llm_with_tools.invoke(messages)
            messages.append(response)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ tool calls
            tool_calls = getattr(response, 'tool_calls', None) or []
            if not tool_calls:
                # –ï—Å–ª–∏ –Ω–µ—Ç tool calls, –ø–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                structured = self.llm.with_structured_output(output_model)
                final_messages = messages + [HumanMessage(
                    content="–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–π —Å–æ–±—Ä–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
                )]
                result: T = structured.invoke(final_messages)
                return result
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º tool calls
            for tool_call in tool_calls:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã tool_call
                if isinstance(tool_call, dict):
                    tool_name = tool_call.get("name", "")
                    tool_args = tool_call.get("args", {})
                    tool_call_id = tool_call.get("id", f"call_{iteration}_{tool_name}")
                else:
                    # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç
                    tool_name = getattr(tool_call, "name", "")
                    tool_args = getattr(tool_call, "args", {})
                    tool_call_id = getattr(tool_call, "id", f"call_{iteration}_{tool_name}")
                
                if not tool_name or tool_name not in tool_map:
                    error_msg = f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {tool_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"
                    messages.append(ToolMessage(content=error_msg, tool_call_id=tool_call_id))
                    continue
                
                # –í—ã–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
                tool = tool_map[tool_name]
                try:
                    print(f"   üîß –í—ã–∑—ã–≤–∞—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool_name}")
                    tool_result = tool.invoke(tool_args)
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –æ–±—Ä–∞—Ç–Ω–æ
                    if not isinstance(tool_result, str):
                        import json
                        tool_result = json.dumps(tool_result, ensure_ascii=False, default=str)
                    
                    messages.append(ToolMessage(content=str(tool_result), tool_call_id=tool_call_id))
                    print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ {tool_name} –ø–æ–ª—É—á–µ–Ω")
                except Exception as e:
                    error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ {tool_name}: {str(e)}"
                    messages.append(ToolMessage(content=error_msg, tool_call_id=tool_call_id))
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ {tool_name}: {e}")
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–π, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        structured = self.llm.with_structured_output(output_model)
        final_messages = messages + [HumanMessage(
            content="–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–π —Å–æ–±—Ä–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        )]
        result: T = structured.invoke(final_messages)
        return result

    def __getattr__(self, name: str) -> Any:
        """
        –í—Å—ë, —á–µ–≥–æ –Ω–µ—Ç —É JourneyLLM, –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ–º –Ω–∞ self.llm:
        .invoke(), .stream(), .bind_tools(), .with_structured_output() –∏ —Ç.–¥.
        """
        return getattr(self.llm, name)

    def __call__(self, *args, **kwargs) -> Any:
        """
        –ß—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ "–º–æ–¥–µ–ª—å":
            llm("–ø—Ä–∏–≤–µ—Ç")  –∏–ª–∏ llm.invoke(...)
        """
        return self.llm(*args, **kwargs)
